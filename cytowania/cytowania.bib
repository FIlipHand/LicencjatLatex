@article{cokolwiek,
   title={An Introduction to Variational Autoencoders},
   volume={12},
   ISSN={1935-8245},
   url={httpdx.doi.org10.15612200000056},
   DOI={10.15612200000056},
   number={4},
   journal={Foundations and Trends® in Machine Learning},
   publisher={Now Publishers},
   author={Kingma, Diederik P. and Welling, Max},
   year={2019},
   pages={307–392}
}

@misc{doersch2021tutorial,
      title={Tutorial on Variational Autoencoders}, 
      author={Carl Doersch},
      year={2021},
      eprint={1606.05908},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@ARTICLE{9244048,
  author={Asperti, Andrea and Trentin, Matteo},
  journal={IEEE Access}, 
  title={Balancing Reconstruction Error and Kullback-Leibler Divergence in Variational Autoencoders}, 
  year={2020},
  volume={8},
  number={},
  pages={199440-199448},
  abstract={Likelihood-based generative frameworks are receiving increasing attention in the deep learning community, mostly on account of their strong probabilistic foundation. Among them, Variational Autoencoders (VAEs) are reputed for their fast and tractable sampling and relatively stable training, but if not properly tuned they may easily produce poor generative performances. The loss function of Variational Autoencoders is the sum of two components, with somehow contrasting effects: the reconstruction loss, improving the quality of the resulting images, and the Kullback-Leibler divergence, acting as a regularizer of the latent space. Correctly balancing these two components is a delicate issue, and one of the major problems of VAEs. Recent techniques address the problem by allowing the network to learn the balancing factor during training, according to a suitable loss function. In this article, we show that learning can be replaced by a simple deterministic computation, expressing the balancing factor in terms of a running average of the reconstruction error over the last minibatches. As a result, we keep a constant balance between the two components along training: as reconstruction improves, we proportionally decrease KL-divergence in order to prevent its prevalence, that would forbid further improvements of the quality of reconstructions. Our technique is simple and effective: it clarifies the learning objective for the balancing factor, and it produces faster and more accurate behaviours. On typical datasets such as Cifar10 and CelebA, our technique sensibly outperforms all previous VAE architectures with comparable parameter capacity.},
  keywords={},
  doi={10.1109/ACCESS.2020.3034828},
  ISSN={2169-3536},
  month={},}
  
@ARTICLE{9166477,  author={Cristovao, Paulino and Nakada, Hidemoto and Tanimura, Yusuke and Asoh, Hideki},  journal={IEEE Access},   title={Generating In-Between Images Through Learned Latent Space Representation Using Variational Autoencoders},   year={2020},  volume={8},  number={},  pages={149456-149467},  abstract={Image interpolation is often implemented using one of two methods: optical flow or convolutional neural networks. These methods are typically pixel-based; they do not work well on objects between images far apart. Because they either rely on a simple frame average or pixel motion, they do not have the required knowledge of the semantic structure of the data. In this paper, we propose a method for image interpolation based on latent representations. We use a simple network structure based on a variational autoencoder and an adjustable hyperparameter that imposes the latent space distribution to generate accurate interpolation. To visualize the effects of the proposed approach, we evaluate a synthetic dataset. We demonstrate that our method outperforms both pixel-based methods and a conventional variational autoencoder, with particular improvements in nonsuccessive images.},  keywords={},  doi={10.1109/ACCESS.2020.3016313},  ISSN={2169-3536},  month={},}

@ARTICLE{8853312,  author={Song, Tianbao and Sun, Jingbo and Chen, Bo and Peng, Weiming and Song, Jihua},  journal={IEEE Access},   title={Latent Space Expanded Variational Autoencoder for Sentence Generation},   year={2019},  volume={7},  number={},  pages={144618-144627},  abstract={Sentence generation is a key task in many natural language processing systems. Models based on a variational autoencoder (VAE) can generate plausible sentences from a continuous latent space. However, the VAE forces the latent distribution of each input sentence to match the same prior, which results in a large overlap among the latent subspaces of different sentences and a limited informative latent space. Therefore, the sentences generated by sampling from a subspace may have little correlation with the corresponding input, and the latent space cannot capture rich useful information from the input sentences, which leads to the failure of the model to generate diverse sentences from the latent space. Additionally, the Kullback-Leibler (KL) divergence collapse problem makes the VAE notoriously difficult to train. In this paper, a latent space expanded VAE (LSE-VAE) model is presented for sentence generation. The model maps each sentence to a continuous latent subspace under the constraint of its own prior distribution, and constrains nearby sentences to map to nearby subspaces. Sentences are dispersed to a large continuous latent space according to sentence similarity, where the latent subspaces of different sentences may be relatively far away from each other and arranged in an orderly manner. The experimental results show that the LSE-VAE improves the reconstruction ability of the VAE, generates plausible and more diverse sentences, and learns a larger informative latent space than the VAE with the properties of continuity and smoothness. The LSE-VAE does not suffer from the KL collapse problem, and it is robust to hyperparameters and much easier to train.},  keywords={},  doi={10.1109/ACCESS.2019.2944630},  ISSN={2169-3536},  month={},}

@INPROCEEDINGS{7979344,  author={Xu, Qingyang and Wu, Zhe and Yang, Yiqin and Zhang, Li},  booktitle={2017 29th Chinese Control And Decision Conference (CCDC)},   title={The difference learning of hidden layer between autoencoder and variational autoencoder},   year={2017},  volume={},  number={},  pages={4801-4804},  abstract={Autoencoder is an excellent unsupervised learning algorithm. However, it can not generate kinds of sample data in the decoding process. Variational autoencoder is a typical generative adversarial net which can generate various data to augment the sample data. In this paper, we want to do some research about the information learning in hidden layer. In the simulation, we compare the hidden layer learning of hidden layer in conventional autoencoder and variational autoencoder.},  keywords={},  doi={10.1109/CCDC.2017.7979344},  ISSN={1948-9447},  month={May},}

@INPROCEEDINGS{8724998,  author={Kim, Min Su and Yun, Jong Pil and Lee, Suwoong and Park, PooGyeon},  booktitle={2019 11th International Symposium on Advanced Topics in Electrical Engineering (ATEE)},   title={Unsupervised Anomaly detection of LM Guide Using Variational Autoencoder},   year={2019},  volume={},  number={},  pages={1-5},  abstract={Linear Motion (LM) is a linear motion guide that helps directional moving of machine. It is important to judge the anomaly state of LM guides because LM guides are used in various industries to support various task in industry application. In this paper, we proposed a machine learning algorithm for determining the anomaly state of LM guide. Considering that it is difficult to actually generate the anomaly signal, we trained model with only healthy state data. One of the generative models, variational autoencoder, is used for training healthy state data and the distribution of healthy state data is trained. Our trained model determines whether or not anomaly state has occurred based on a reconstruction error of the trained network.},  keywords={},  doi={10.1109/ATEE.2019.8724998},  ISSN={2159-3604},  month={March},}

@INPROCEEDINGS{8091468,  author={Xu, Qingyang and Yang, Yiqin and Wu, Zhe and Zhang, Li},  booktitle={2017 4th International Conference on Information, Cybernetics and Computational Social Systems (ICCSS)},   title={Different latent variables learning in variational autoencoder},   year={2017},  volume={},  number={},  pages={508-511},  abstract={Unsupervised learning is a good neural network training way. However, the unsupervised learning algorithm is rare. The generative model is an interesting algorithm which can generate the similar data as the sample data by building a probabilistic model of the input data, and it can be used for unsupervised learning. Variational autoencoder is a typical generative model which is different from common autoencoder that a probabilistic parameter layer follows the hidden layer. Some new data can be reconstructed according to probabilistic model parameters. The probabilistic model parameter is the latent variable. In this paper, we want to do some research to test the data reconstruct effect of the variational autoencoder by different latent variables. According to the simulation, the more latent variables the more style of the sample is.},  keywords={},  doi={10.1109/ICCSS.2017.8091468},  ISSN={},  month={July},}

@INPROCEEDINGS{9107633,  author={Tu, Ching-Ting and Chen, Yi-Fu},  booktitle={2019 2nd International Conference of Intelligent Robotic and Control Engineering (IRCE)},   title={Facial Image Inpainting with Variational Autoencoder},   year={2019},  volume={},  number={},  pages={119-122},  abstract={This paper proposed a learning-based approach to reveal diversity possible appearances under the missing area of an occluded unseen image. In general, there are a lot of possible facial appearances for the missing area; for example, a male with a scarf, it is difficult to predict he has a beard in the covered area or not? In this paper, we propose a novel method for facial image inpainting, which generates the missing facial appearance by conditioning on the observable appearance. Given a trained standard Variational Autoencoder (VAE) for un-occluded face generation. To be specified, we search for the possible set of VAE coding vector for the current occluded input image, and the predicted coding should be robust to the missing area. The possible facial appearance set is then recovered through the decoder of VAE model. Experiments show that our method successfully predicts recovered results in large missing regions; these results are diverse, and all are reasonable to be consistent with the observable facial area, i.e., both the facial geometry and the personal characteristics are preserved.},  keywords={},  doi={10.1109/IRCE.2019.00031},  ISSN={},  month={Aug},}

@misc{bank2021autoencoders,
      title={Autoencoders}, 
      author={Dor Bank and Noam Koenigstein and Raja Giryes},
      year={2021},
      eprint={2003.05991},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{mnist,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@misc{kingma2014autoencoding,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2014},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{eldan2016power,
      title={The Power of Depth for Feedforward Neural Networks}, 
      author={Ronen Eldan and Ohad Shamir},
      year={2016},
      eprint={1512.03965},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{telgarsky2016benefits,
      title={Benefits of depth in neural networks}, 
      author={Matus Telgarsky},
      year={2016},
      eprint={1602.04485},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{deepimageimpainting,
      title={Deep Image Inpainting}, 
      author={Charles Burlin, Yoann Le Calonnec, Louis Duperier},
      year={2017}
}

@misc{redukcjawymiarow,
      title={Wybrane metody redukcji wymiarowości danych oraz ich wizualizacji}, 
      author={Jarosław Gramack and Artur Gramacki},
      year={2008}
}
@misc{aevspca,
      title={From Principal Subspaces to Principal Components with Linear Autoencoders}, 
      author={Elad Plaut},
      year={2018},
      eprint={1804.10253},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{porownaniakompresji,
   title={Empirical Comparison between Autoencoders and Traditional Dimensionality Reduction Methods},
   url={http://dx.doi.org/10.1109/AIKE.2019.00044},
   DOI={10.1109/aike.2019.00044},
   journal={2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)},
   publisher={IEEE},
   author={Fournier, Quentin and Aloise, Daniel},
   year={2019},
   month={Jun}
}

@misc{soch2016kullbackleibler,
      title={Kullback-Leibler Divergence for the Normal-Gamma Distribution}, 
      author={Joram Soch and Carsten Allefeld},
      year={2016},
      eprint={1611.01437},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@misc{relu,
      title={Deep Sparse Rectifier Neural Networks}, 
      author={Xavier Glorot, Antoine Bordes and Yoshua Bengio},
      year={2011},
}

@misc{adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}